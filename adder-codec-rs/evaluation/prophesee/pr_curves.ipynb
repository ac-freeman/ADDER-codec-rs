{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c763944fce9a995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:57:04.330559620Z",
     "start_time": "2024-03-01T20:57:04.287467887Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:03:49.586592926Z",
     "start_time": "2024-03-05T14:03:49.581279362Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '/media/andrew/One Touch/HMNET2_crf0')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Copyright (c) Prophesee S.A.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "# \n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "# \n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n",
    "# or implied. See the License for the specific language governing\n",
    "# permissions and limitations under the License.\n",
    "\n",
    "# This file is modified from the original code at\n",
    "# https://github.com/prophesee-ai/prophesee-automotive-dataset-toolbox/blob/master/src/psee_evaluator.py\n",
    "# The list of modifications are as follows:\n",
    "# (1) \"min_box_side\" for box filtering is modified following the previous work:\n",
    "#     Perot, Etienne, et al. \"Learning to detect objects with a 1 megapixel event camera.\" Advances in Neural Information Processing Systems 33 (2020): 16639-16652.\n",
    "# (2) Configs for GEN1 and GEN4 are added and passed to \"evaluate_detection\"\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "from numpy.lib import recfunctions as rfn\n",
    "\n",
    "from coco_eval import evaluate_detection\n",
    "from hmnet.utils.psee_toolbox.io.box_filtering import filter_boxes\n",
    "from hmnet.utils.psee_toolbox.io.box_loading import reformat_boxes\n",
    "from hmnet.utils.common import get_list, mkdir\n",
    "\n",
    "EVAL_CONF_GEN1 = dict(\n",
    "    classes = ('car', 'pedestrian'),\n",
    "    width = 304,\n",
    "    height = 240,\n",
    "    time_tol = 25000, # +/- 25 msec (50 msec)\n",
    ")\n",
    "\n",
    "EVAL_CONF_GEN4 = dict(\n",
    "    classes = ('pedestrian', 'two wheeler', 'car', 'truck', 'bus', 'traffic sign', 'traffic light'),\n",
    "    width = 1280,\n",
    "    height = 720,\n",
    "    time_tol = 25000, # +/- 25 msec (50 msec)\n",
    ")\n",
    "\n",
    "def evaluate_folders(dt_folder, gt_lst, camera):\n",
    "    dt_file_paths = get_list(dt_folder, ext='npy')\n",
    "    gt_file_paths = get_list(gt_lst, ext='npy')\n",
    "\n",
    "    filtered_paths = []\n",
    "    for path in gt_file_paths:\n",
    "    # Check if any reference path is a substring of the current path\n",
    "        if any(ref.split('/')[-1].rsplit(\"_\", 1)[0] in path for ref in dt_file_paths):\n",
    "            filtered_paths.append(path)\n",
    "\n",
    "    gt_file_paths = filtered_paths\n",
    "\n",
    "    # assert len(dt_file_paths) == len(gt_file_paths)\n",
    "    print(\"There are {} GT bboxes and {} PRED bboxes\".format(len(gt_file_paths), len(dt_file_paths)))\n",
    "    result_boxes_list = [np.load(p) for p in dt_file_paths]\n",
    "    gt_boxes_list = [np.load(p) for p in gt_file_paths]\n",
    "    gt_boxes_list = [ rfn.drop_fields(p, 'invalid') for p in gt_boxes_list ]\n",
    "\n",
    "    result_boxes_list = [reformat_boxes(p) for p in result_boxes_list]\n",
    "    gt_boxes_list = [reformat_boxes(p) for p in gt_boxes_list]\n",
    "\n",
    "    min_box_diag = 60 if camera == 'GEN4' else 30\n",
    "    min_box_side = 20 if camera == 'GEN4' else 10\n",
    "    eval_conf = EVAL_CONF_GEN4 if camera == 'GEN4' else EVAL_CONF_GEN1\n",
    "\n",
    "    filter_boxes_fn = lambda x:filter_boxes(x, int(5e5), min_box_diag, min_box_side)\n",
    "\n",
    "    gt_boxes_list = map(filter_boxes_fn, gt_boxes_list)\n",
    "    result_boxes_list = map(filter_boxes_fn, result_boxes_list)\n",
    "    coco_eval = evaluate_detection(gt_boxes_list, result_boxes_list, **eval_conf)\n",
    "    # print(coco_eval.curve_df.to_string())\n",
    "    \n",
    "    # Plot the PR curve\n",
    "    return coco_eval.curve_df_small, coco_eval.curve_df_medium, coco_eval.curve_df_large, coco_eval.curve_df\n",
    "    \n",
    "\n",
    "gt_dir = \"/media/andrew/One Touch/HMNET2_crf9_shrink/experiments/detection/data/gen1/test_lbl/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea548ee2458527b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:03:52.495811401Z",
     "start_time": "2024-03-05T14:03:52.491306653Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotem(adder_dir, shrink_dir):\n",
    "\n",
    "    results_dir = \"/media/andrew/One Touch/HMNET2_crf9/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\"\n",
    "    small, medium, large, alll = evaluate_folders(adder_dir, gt_dir, 'GEN1')\n",
    "    \n",
    "    results_dir = \"/media/andrew/One Touch/HMNET2_crf9_shrink/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\"\n",
    "    small_s, medium_s, large_s, alll_s = evaluate_folders(shrink_dir, gt_dir, 'GEN1')\n",
    "    \n",
    "    plt.plot(small['threshold'], small['precision'])\n",
    "    plt.plot(small_s['threshold'], small_s['precision'])\n",
    "    plt.show()\n",
    "    plt.plot(medium['threshold'], medium['precision'])\n",
    "    plt.plot(medium_s['threshold'], medium_s['precision'])\n",
    "    plt.show()\n",
    "    plt.plot(large['threshold'], large['precision'])\n",
    "    plt.plot(large_s['threshold'], large_s['precision'])\n",
    "    plt.show()\n",
    "    plt.plot(alll['threshold'], alll['precision'])\n",
    "    plt.plot(alll_s['threshold'], alll_s['precision'])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb1f18108bbb92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:13:53.633406990Z",
     "start_time": "2024-03-05T14:13:46.235507407Z"
    }
   },
   "outputs": [],
   "source": [
    "plotem(\"/media/andrew/One Touch/HMNET2_crf9/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\", \"/media/andrew/One Touch/HMNET2_crf9_shrink/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc12ff510b6f22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:57:17.345985235Z",
     "start_time": "2024-03-01T20:57:10.568407472Z"
    }
   },
   "outputs": [],
   "source": [
    "plotem(\"/media/andrew/One Touch/HMNET2_crf6/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\", \"/media/andrew/One Touch/HMNET2_crf6_shrink/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7d46c342c692e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:57:24.523411063Z",
     "start_time": "2024-03-01T20:57:17.346684633Z"
    }
   },
   "outputs": [],
   "source": [
    "plotem(\"/media/andrew/One Touch/HMNET2_crf3/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\", \"/media/andrew/One Touch/HMNET2_crf3_shrink/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107ca688e4dfc74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-01T20:57:31.911865095Z",
     "start_time": "2024-03-01T20:57:24.521369580Z"
    }
   },
   "outputs": [],
   "source": [
    "plotem(\"/media/andrew/One Touch/HMNET2_crf0/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\", \"/media/andrew/One Touch/HMNET2_crf0_shrink/experiments/detection/workspace/hmnet_B3_yolox_tbptt/result/pred_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
