{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T14:30:39.798660318Z",
     "start_time": "2024-02-29T14:30:39.750930492Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def size_without_header(file_path):\n",
    "    # print(\"opening\", file_path)\n",
    "        # Read the first lines of the file until we reach some non-text (binary) data\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            # print(\"opened\", file_path)\n",
    "            # Read line by line until an exception is thrown or the end of file is reached\n",
    "            header = \"\"\n",
    "            \n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                # print(line)\n",
    "                if line == \"\":\n",
    "                    break\n",
    "                header += line.decode(\"utf-8\")\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "        # Now we know the header, we can get the size of the file\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        file.seek(0, os.SEEK_END)\n",
    "        file_size = file.tell()\n",
    "        # Subtract the size of the header from the file size\n",
    "        file_size -= len(header)\n",
    "    return file_size\n",
    "\n",
    "data_root = '/media/andrew/One Touch/HMNET_ADDER_data'\n",
    "gt_directory_path = '/media/andrew/One Touch/HMNET2/experiments/detection/data/gen1/source/detection_dataset_duration_60s_ratio_1.0/test'\n",
    "\n",
    "total_count = 0\n",
    "df = pd.DataFrame(columns=['filename', 'crf', 'gt_bytes', 'shrunk_bytes', 'pct_shrunk'])\n",
    "\n",
    "for i in [0,3,6,9]:\n",
    "    # look in ./gen${i} and get the file list\n",
    "    input_directory_path = gt_directory_path\n",
    "    output_directory_path = os.path.join(data_root, f'gen{i}_dat')\n",
    "    os.makedirs(output_directory_path, exist_ok=True)\n",
    "    \n",
    "    file_list = os.listdir(input_directory_path)\n",
    "    file_list = [filename for filename in file_list if filename.endswith('.dat')]\n",
    "    \n",
    "    for filename in file_list:\n",
    "        \n",
    "        # get filename without extension\n",
    "        filename_out = filename.split('.')[0]+'.dat'\n",
    "            \n",
    "        input_file_path = os.path.join(input_directory_path, filename)\n",
    "        output_file_path = os.path.join(output_directory_path, filename_out)\n",
    "        \n",
    "        if filename_out in already_done_files and os.path.getsize(output_file_path) > 100:\n",
    "            total_count = total_count + 1\n",
    "            \n",
    "            crf = i\n",
    "            gt_bytes = size_without_header(input_file_path)\n",
    "            shrunk_bytes = size_without_header(output_file_path)\n",
    "            pct_shrunk = (gt_bytes - shrunk_bytes) / gt_bytes * 100\n",
    "    \n",
    "            # Create a new row and append it to the DataFrame\n",
    "            new_row = pd.DataFrame({'filename': [filename_out], 'crf': [crf], 'gt_bytes': [gt_bytes], 'shrunk_bytes': [shrunk_bytes], 'pct_shrunk': [pct_shrunk]})\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    print(\"CRF\", i, \"done\")\n",
    "    \n",
    "print(\"Total count\", total_count)\n",
    "print(df)\n",
    "df.to_csv('shrunk_files.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
