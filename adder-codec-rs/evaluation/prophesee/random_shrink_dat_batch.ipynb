{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T23:35:09.864879438Z",
     "start_time": "2024-02-27T23:20:06.620500210Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import ctypes\n",
    "c_longlong = ctypes.c_longlong\n",
    "\n",
    "def size_without_header(file_path):\n",
    "    # print(\"opening\", file_path)\n",
    "        # Read the first lines of the file until we reach some non-text (binary) data\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            # print(\"opened\", file_path)\n",
    "            # Read line by line until an exception is thrown or the end of file is reached\n",
    "            header = \"\"\n",
    "            \n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                # print(line)\n",
    "                if line == \"\":\n",
    "                    break\n",
    "                header += line.decode(\"utf-8\")\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "        \n",
    "        # Now we know the header, we can get the size of the file\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        file.seek(0, os.SEEK_END)\n",
    "        file_size = file.tell()\n",
    "        # Subtract the size of the header from the file size\n",
    "        file_size -= len(header)\n",
    "    return file_size\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "gt_directory_path = '/media/andrew/One Touch/HMNET2/experiments/detection/data/gen1/source/detection_dataset_duration_60s_ratio_1.0/test'\n",
    "adder_shrunk_directory_root = '/media/andrew/One Touch/HMNET_ADDER_data'\n",
    "output_directory_root = '/media/andrew/One Touch/HMNET_ADDER_data'\n",
    "\n",
    "gt_file_list = os.listdir(gt_directory_path)\n",
    "# Filter to just those ending int .dat\n",
    "gt_file_list = [filename for filename in gt_file_list if filename.endswith('.dat')]\n",
    "\n",
    "for i in [3,6,9]:\n",
    "    print(\"CRF: \", i)\n",
    "    adder_directory_path = os.path.join(output_directory_root, f'gen{i}_dat')\n",
    "    output_directory_path = os.path.join(output_directory_root, f'gen{i}_random_shrink')\n",
    "    os.makedirs(output_directory_path, exist_ok=True)\n",
    "    already_done_files = os.listdir(output_directory_path)\n",
    "    \n",
    "    for filename in gt_file_list:\n",
    "        if filename in already_done_files:\n",
    "            continue\n",
    "        else:\n",
    "            print(filename)\n",
    "            # Do the thing\n",
    "            # 1. Load the file\n",
    "            # Get the size of the ADDER version in bytes\n",
    "            adder_file_path = os.path.join(adder_directory_path, filename)\n",
    "            # If the ADDER file doesn't exist, then we can't shrink it\n",
    "            if not os.path.exists(adder_file_path):\n",
    "                print(f'ADDER file {filename} does not exist. Skipping')\n",
    "                continue\n",
    "            \n",
    "            adder_file_size = size_without_header(adder_file_path)\n",
    "            num_adder_version_events = adder_file_size // 8\n",
    "            # Get the size of the GT version in bytes\n",
    "            gt_file_path = os.path.join(gt_directory_path, filename)\n",
    "            gt_file_size = size_without_header(gt_file_path)\n",
    "            num_gt_version_events = gt_file_size // 8\n",
    "            \n",
    "            # If the GT version is smaller than the ADDER version, then we can't shrink it\n",
    "            if gt_file_size < adder_file_size:\n",
    "                print(f'GT file {filename} is smaller than ADDER file {filename}. Skipping')\n",
    "                continue\n",
    "            # If the GT version is the same size as the ADDER version, then we don't need to shrink it\n",
    "            elif gt_file_size == adder_file_size:\n",
    "                print(f'GT file {filename} is the same size as ADDER file {filename}. Skipping')\n",
    "                continue\n",
    "            # If the GT version is larger than the ADDER version, then we can shrink it\n",
    "            else:\n",
    "                print(f'GT file {filename} is larger than ADDER file {filename}. Shrinking')\n",
    "                # Randomly remove events from the GT version until it is the same size as the ADDER version\n",
    "                # Load the GT file\n",
    "                try:\n",
    "                    with open(gt_file_path, \"rb\") as file:\n",
    "                      # Read line by line until an exception is thrown or the end of file is reached\n",
    "                      header = \"\"\n",
    "                      for line in file:\n",
    "                        header += line.decode(\"utf-8\")\n",
    "                \n",
    "                except UnicodeDecodeError:\n",
    "                    pass\n",
    "                \n",
    "                with open(gt_file_path, \"rb\") as file:\n",
    "                    # seek to the end of the header\n",
    "                    file.seek(len(header))\n",
    "                    # Read the rest of the file\n",
    "                    data = file.read()\n",
    "                # Convert the data to a list of 8-byte integers\n",
    "                data = [data[i:i+8] for i in range(0, len(data), 8)]\n",
    "                print(type(data[0]))\n",
    "\n",
    "                \n",
    "                print(\"Need to remove\", len(data) - num_adder_version_events, \"events\")\n",
    "                \n",
    "                # Randomly remove events until the file is the same size as the ADDER version\n",
    "                \n",
    "                data_array = np.array(data, dtype=object)\n",
    "\n",
    "                # Select N random indices using NumPy's random.choice\n",
    "                random_indices = np.random.choice(len(data_array), size=len(data_array)-num_adder_version_events, replace=False)\n",
    "            \n",
    "                # Sort the indices in ascending order to preserve removal order\n",
    "                random_indices.sort()\n",
    "            \n",
    "                # Create a mask to select elements to keep (excluding the random indices)\n",
    "                mask = np.ones(len(data_array), dtype=bool)\n",
    "                mask[random_indices] = False\n",
    "            \n",
    "                # Use boolean indexing to filter the data and get the removed items\n",
    "                modified_data = data_array[mask]\n",
    "                removed_items = data_array[random_indices]\n",
    "            \n",
    "                # Convert the NumPy arrays back to lists if desired\n",
    "                data = modified_data.tolist()\n",
    "\n",
    "                \n",
    "                \n",
    "                # Convert the data back to bytes\n",
    "                data = b''.join([x for x in data])\n",
    "                # Save the file\n",
    "                output_file_path = os.path.join(output_directory_path, filename)\n",
    "                with open(output_file_path, 'wb') as f:\n",
    "                    f.write(header.encode('utf-8'))\n",
    "                    f.write(data)\n",
    "                # Add the file to the already_done_files list\n",
    "                \n",
    "                \n",
    "            \n",
    "            # 2. Shrink the file\n",
    "            # 3. Save the file\n",
    "            # 4. Add the file to the already_done_files list\n",
    "            # 5. Repeat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
