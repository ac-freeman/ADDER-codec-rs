{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:42:52.975491052Z",
     "start_time": "2023-11-02T15:42:52.907578025Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get the current directory\n",
    "current_directory = '/home/andrew/Downloads/Predictions1'\n",
    "\n",
    "# Regular expression to extract the [name] portion\n",
    "pattern = r'(\\d+)_(.*?)_(.*?)_(.*?)_(\\d{2}_\\d{2}_\\d{4}_\\d{2}_\\d{2}_\\d{2})\\.log'\n",
    "\n",
    "# Create a dictionary to store filenames by [name]\n",
    "name_to_files = {}\n",
    "\n",
    "# List all files with a .log extension in the current directory\n",
    "log_files = [file for file in os.listdir(current_directory) if file.endswith(\".log\")]\n",
    "\n",
    "\n",
    "# Function to parse the timestamp string into a datetime object\n",
    "def parse_timestamp(timestamp_str):\n",
    "    return datetime.strptime(timestamp_str, '%d_%m_%Y_%H_%M_%S')\n",
    "\n",
    "\n",
    "# Iterate through log files and group them by [name]\n",
    "for log_file in log_files:\n",
    "    match = re.search(pattern, log_file)\n",
    "    if match:\n",
    "        name = match.group(4)\n",
    "        timestamp_str = match.group(5)\n",
    "        timestamp = parse_timestamp(timestamp_str)\n",
    "\n",
    "        if name not in name_to_files:\n",
    "            name_to_files[name] = []\n",
    "        name_to_files[name].append((timestamp, log_file))\n",
    "\n",
    "# Print the grouped filenames\n",
    "for name, files in name_to_files.items():\n",
    "    print(f\"[name]: {name}\")\n",
    "    sorted_files = sorted(files, key=lambda x: x[0])  # Sort by timestamp\n",
    "    for _timestamp, file in sorted_files:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8aceef95fc1f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T17:45:19.825790959Z",
     "start_time": "2023-11-02T17:45:19.693858318Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class InputSet:\n",
    "    def __init__(self, height, width, ):\n",
    "        self.event_bitrate = None\n",
    "        self.compressed_bitrate = None\n",
    "        self.adder_feature_count = None\n",
    "        self.adder_time = None\n",
    "        self.cv_feature_count = None\n",
    "        self.cv_time = None\n",
    "        self.psnr = None\n",
    "        self.mse = None\n",
    "        self.ssim = None\n",
    "        self.recon_psnr = None\n",
    "        self.recon_mse = None\n",
    "        self.recon_ssim = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.accuracy = None\n",
    "\n",
    "\n",
    "def process_entry(entry, input_sets):\n",
    "    if 's' in entry:\n",
    "        if \"OpenCV\" in entry['s']:\n",
    "            input_sets[-1].cv_features[entry['y'], entry['x']] = True\n",
    "        elif \"ADDER\" in entry['s']:\n",
    "            input_sets[-1].adder_features[entry['y'], entry['x']] = True\n",
    "        else:\n",
    "            raise Exception(\"Malformed entry\")\n",
    "    elif 'psnr' in entry:\n",
    "        input_sets[-1].psnr = entry['psnr']\n",
    "        input_sets[-1].mse = entry['mse']\n",
    "        input_sets[-1].ssim = entry['ssim']\n",
    "        \n",
    "def process_recon_entry(entry, input_sets, idx):\n",
    "    if 'psnr' in entry:\n",
    "        input_sets[idx].recon_psnr = entry['psnr']\n",
    "        input_sets[idx].recon_mse = entry['mse']\n",
    "        input_sets[idx].recon_ssim = entry['ssim']\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "Stage = Enum('Stage', ['RAW', 'RECON', 'COMPRESS_SIZE'])\n",
    "\n",
    "def read_logfile(path):\n",
    "    objects = []\n",
    "    with (\n",
    "            open(\n",
    "                path,\n",
    "                \"rb\")) as openfile:\n",
    "        # Read the dimensions\n",
    "        dims = openfile.readline().decode('UTF-8')\n",
    "        # print(dims)\n",
    "        width = int(dims.split('x')[0])\n",
    "        height = int(dims.split('x')[1])\n",
    "        channels = int(dims.split('x')[2])\n",
    "\n",
    "        dbg_lines = 0\n",
    "        input_interval_idx = 0\n",
    "        input_sets = [InputSet(height, width)]\n",
    "        recon = False\n",
    "        input_set_index = 0\n",
    "        stage = Stage.RAW\n",
    "        adu_interval = None\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                entry = pickle.load(openfile)\n",
    "                if type(entry) == str and \"ADDER FAST:\" in entry:\n",
    "                    # The start of a new interval\n",
    "                    time = entry.split(': ')[1]\n",
    "                    input_sets[-1].adder_time = int(time)\n",
    "                    continue\n",
    "                elif type(entry) == str and \"bps:\" in entry:\n",
    "                    # The bitrate\n",
    "                    # The end of the interval\n",
    "                    bitrate = float(entry.split(': ')[1]) / 1024.0 / 1024.0\n",
    "                    input_sets[-1].event_bitrate = bitrate\n",
    "\n",
    "                    input_sets += [InputSet(height, width)]\n",
    "                    input_interval_idx += 1\n",
    "                    continue\n",
    "                elif type(entry) == str and \"RECONSTRUCTION\" in entry:\n",
    "                    stage = Stage.RECON\n",
    "                    input_set_index = 0\n",
    "                elif type(entry) == str and \"Compressed adu\" in entry:\n",
    "                    stage = Stage.COMPRESS_SIZE\n",
    "                    input_set_index = 0\n",
    "                elif type(entry) == str and \"OpenCV FAST:\" in entry:\n",
    "                    time = entry.split(': ')[1]\n",
    "                    input_sets[-1].cv_time = int(time)\n",
    "\n",
    "                elif type(entry) == str and \"META:\" in entry:\n",
    "                    print(entry)\n",
    "                    continue\n",
    "                elif type(entry) == str and \"Feature results:\" in entry:\n",
    "                    precision = pickle.load(openfile)\n",
    "                    input_sets[-1].precision = precision\n",
    "                    recall = pickle.load(openfile)\n",
    "                    input_sets[-1].recall = recall\n",
    "                    accuracy = pickle.load(openfile)\n",
    "                    input_sets[-1].accuracy = accuracy\n",
    "                    \n",
    "                elif type(entry) == int:\n",
    "                    if stage == stage.RAW:\n",
    "                        if input_sets[-1].adder_feature_count is None:\n",
    "                            input_sets[-1].adder_feature_count = entry\n",
    "                        else:\n",
    "                            input_sets[-1].cv_feature_count = entry\n",
    "                    elif stage == stage.COMPRESS_SIZE:\n",
    "                        for i in range(input_set_index, input_set_index + adu_interval):\n",
    "                            input_sets[i].compressed_bitrate = (entry * 8) / 1024 /1024 # Mb/s\n",
    "                        input_set_index += adu_interval\n",
    "                    else:\n",
    "                        raise Exception(\"unexpected int\")\n",
    "                    \n",
    "                else:\n",
    "                    if stage == Stage.RAW:\n",
    "                        process_entry(entry, input_sets)\n",
    "                    elif stage == Stage.RECON:\n",
    "                        process_recon_entry(entry, input_sets, input_set_index)\n",
    "                        input_set_index += 1\n",
    "                    elif stage == Stage.COMPRESS_SIZE:\n",
    "                        print('here')\n",
    "                        break\n",
    "\n",
    "                    # print(entry)\n",
    "                    dbg_lines += 1\n",
    "                    # if dbg_lines == 100000:\n",
    "                    #     break\n",
    "            except pickle.UnpicklingError:\n",
    "                line = openfile.readline().decode('UTF-8')\n",
    "                if \"Ticks per second\" in line:\n",
    "                    tps = int(line.split(': ')[2])\n",
    "                elif \"ticks per source interval\" in line:\n",
    "                    tpf = int(line.split(': ')[2])\n",
    "                elif \"t_max\" in line:\n",
    "                    dt_max = int(line.split(': ')[2])\n",
    "                    adu_interval = int(dt_max / tpf)\n",
    "                # break\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "        # Remove the last item because it might have none values\n",
    "        input_sets = input_sets[:-1]\n",
    "        if stage == Stage.RAW:\n",
    "             raise Exception(\"Did not perform reconstruction!\")\n",
    "        return input_sets, width, height, channels, tps, tpf\n",
    "    \n",
    "print(sorted_files[0][1])\n",
    "input_sets, width, height, channels, tps, tpf = read_logfile(current_directory + '/' + sorted_files[0][1])\n",
    "\n",
    "print('\\nAll done')\n",
    "print(input_sets[0].recon_psnr)\n",
    "print(input_sets[0].compressed_bitrate)\n",
    "print(input_sets[30].compressed_bitrate)\n",
    "\n",
    "print(sorted_files[1][1])\n",
    "input_sets, width, height, channels, tps, tpf = read_logfile(current_directory + '/' + sorted_files[1][1])\n",
    "\n",
    "print('\\nAll done')\n",
    "print(input_sets[0].recon_psnr)\n",
    "print(input_sets[0].compressed_bitrate)\n",
    "print(input_sets[30].compressed_bitrate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd46c207de7cf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:42:52.991932574Z",
     "start_time": "2023-11-02T15:42:52.964588693Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "\n",
    "\n",
    "def feature_count_plot_all(sets):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    for i, input_sets in enumerate(sets):\n",
    "        adder_feature_count = [obj.adder_feature_count for obj in input_sets]\n",
    "        cv_feature_count = [obj.cv_feature_count for obj in input_sets]\n",
    "\n",
    "        sns.lineplot(x=range(len(input_sets) - 1), y=adder_feature_count[:-1], marker=None, label=\"ADDER_\" + str(i))\n",
    "        sns.lineplot(x=range(len(input_sets) - 1), y=cv_feature_count[:-1], marker=None, label=\"OpenCV_\" + str(i))\n",
    "\n",
    "    plt.ylabel(\"# features\")\n",
    "    plt.xlabel(\"Input frame\")\n",
    "    plt.title(\"Feature count over time\")\n",
    "    plt.show()\n",
    "    # interactive_plot = mpld3.display()\n",
    "    # interactive_plot\n",
    "\n",
    "\n",
    "def feature_speed_plot_all(sets):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    assert sets[0][4].adder_time is None\n",
    "    for i, input_sets in enumerate(sets[1::2]):\n",
    "        adder_times = [obj.adder_time for obj in input_sets]\n",
    "        cv_times = [obj.cv_time for obj in input_sets]\n",
    "\n",
    "        sns.lineplot(x=range(len(input_sets)), y=adder_times, marker=None, label=\"ADDER_\" + str(i))\n",
    "        sns.lineplot(x=range(len(input_sets)), y=cv_times, marker=None, label=\"OpenCV_\" + str(i))\n",
    "    plt.ylabel(\"Time (ns)\")\n",
    "    plt.xlabel(\"Input frame\")\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"Feature detection speed\")\n",
    "\n",
    "    plt.show()\n",
    "    # interactive_plot = mpld3.display()\n",
    "    # interactive_plot\n",
    "\n",
    "    cv_mean = np.mean(np.array(cv_times))\n",
    "    adder_mean = np.mean(np.array(adder_times))\n",
    "    percent_change = (adder_mean / cv_mean) - 1\n",
    "    print('OpenCV mean:', cv_mean, '  Median:', np.median(np.array(cv_times)))\n",
    "    print('ADDER mean:', adder_mean, \"({:.1f}%)\".format(percent_change * 100), '  Median:',\n",
    "          np.median(np.array(adder_times)))\n",
    "\n",
    "\n",
    "def bitrates_plot_all(sets, width, height, channels, tps, tpf):\n",
    "    bitrates_plot_partial(sets[::2], width, height, channels, tps, tpf)\n",
    "    bitrates_plot_partial(sets[1::2], width, height, channels, tps, tpf)\n",
    "    \n",
    "def bitrates_plot_partial(sets, width, height, channels, tps, tpf):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    for i, input_sets in enumerate(sets):\n",
    "        adder_bitrates = [obj.event_bitrate for obj in input_sets]\n",
    "\n",
    "        total_adder_size = np.sum(adder_bitrates) / (tps / tpf)\n",
    "        print(total_adder_size, \"Mb\")\n",
    "\n",
    "        source_raw_Mbps = (width * height * channels * (tps / tpf) * 8.0) / 1024.0 / 1024.0\n",
    "        total_raw_size = (width * height * channels * len(adder_bitrates) * 8.0) / 1024.0 / 1024.0\n",
    "        print(total_raw_size, \"Mb\")\n",
    "        framed_bitrates = [source_raw_Mbps for obj in input_sets]\n",
    "\n",
    "        sns.lineplot(x=range(len(input_sets)), y=adder_bitrates, marker=None, label=\"ADDER_\" + str(i))\n",
    "        sns.lineplot(x=range(len(input_sets)), y=framed_bitrates, marker=None, label=\"OpenCV_\" + str(i))\n",
    "    plt.ylabel(\"Raw bitrate (Mb/s)\")\n",
    "    plt.xlabel(\"Input frame\")\n",
    "    # plt.yscale('log')\n",
    "    plt.title(\"Bitrate\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def quality_plot_all(sets):\n",
    "    quality_plot_partial(sets[::2])  # Without features\n",
    "    plt.title(\"Quality metrics-raw_nofeatures\")\n",
    "    \n",
    "    quality_plot_partial(sets[1::2]) # With features\n",
    "    plt.title(\"Quality metrics-raw_features\")\n",
    "    print(\"recon quality:\")\n",
    "    quality_plot_partial(sets[::2],recon=True)  # Without features\n",
    "    plt.title(\"Quality metrics-recon_nofeatures\")\n",
    "    quality_plot_partial(sets[1::2],recon=True) # With features\n",
    "    plt.title(\"Quality metrics-recon_features\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def quality_plot_partial(sets, recon=False):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # PSNR\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i, input_sets in enumerate(sets):\n",
    "        if recon:\n",
    "            adder_mse = [obj.recon_mse for obj in input_sets]\n",
    "        else: \n",
    "            adder_mse = [obj.mse for obj in input_sets]\n",
    "        sns.lineplot(x=range(len(input_sets)), y=adder_mse, marker=None, label=\"MSE_\" + str(i))\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Input frame\")\n",
    "    plt.title(\"Quality metrics\")\n",
    "    \n",
    "    # # SSIM\n",
    "    # plt.figure(figsize=(8, 4))\n",
    "    # for i, input_sets in enumerate(sets):\n",
    "    #     if recon:\n",
    "    #         adder_ssim = [obj.recon_ssim for obj in input_sets]\n",
    "    #     else: \n",
    "    #         adder_ssim = [obj.ssim for obj in input_sets]\n",
    "    #     \n",
    "    #     sns.lineplot(x=range(len(input_sets)), y=adder_ssim, marker=None, label=\"SSIM_\" + str(i))\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.xlabel(\"Input frame\")\n",
    "    # plt.title(\"Quality metrics\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ca67a10ca1bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T17:18:46.443969294Z",
     "start_time": "2023-11-02T17:18:46.296100948Z"
    }
   },
   "outputs": [],
   "source": [
    "COLOR_MAP = sns.color_palette(\"husl\", 4)\n",
    "\n",
    "\n",
    "def plot_mean_bitrate(sets, feat=False, recon=False):\n",
    "    if feat:\n",
    "        sets = sets[1::2]\n",
    "    else:\n",
    "        sets = sets[::2]\n",
    "    plot_mean_bitrate_partial(sets, recon)\n",
    "    \n",
    "def plot_mean_bitrate_partial(sets, recon=False):\n",
    "    running_bitrate = 0\n",
    "\n",
    "    for i, input_sets in enumerate(sets):\n",
    "        # Get the mean adder bitrate\n",
    "        if recon:\n",
    "            adder_bitrates = [obj.compressed_bitrate for obj in input_sets if obj.compressed_bitrate is not None]\n",
    "            adder_quality = [obj.recon_psnr for obj in input_sets if obj.recon_psnr is not None]\n",
    "        else:\n",
    "            adder_bitrates = [obj.event_bitrate for obj in input_sets if obj.event_bitrate is not None]\n",
    "            adder_quality = [obj.psnr for obj in input_sets if obj.psnr is not None]\n",
    "            \n",
    "        mean_bitrate = np.sum(adder_bitrates)/ len(adder_bitrates)\n",
    "        adder_quality = [min(x, 50.0) for x in adder_quality] # TODO: Mention in paper that we cap PSNR at 50 for practical reasons\n",
    "        mean_quality = np.sum(adder_quality)/ len(adder_quality)\n",
    "        # if mean_quality < 1.0:\n",
    "        #     mean_quality = 1.0\n",
    "        running_bitrate += mean_bitrate \n",
    "        \n",
    "        if i > 0:\n",
    "            # plot the line\n",
    "            plt.plot([last_bitrate, mean_bitrate], [last_quality, mean_quality], c=COLOR_MAP[i], label='Line', alpha=0.5)\n",
    "        # plot this as a single point\n",
    "        plt.scatter( mean_bitrate, mean_quality, c=COLOR_MAP[i], marker='o', label='Point', alpha=0.5)    \n",
    "        \n",
    "        last_bitrate = mean_bitrate\n",
    "        last_quality = mean_quality\n",
    "    # running_bitrate /= len(sets)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16cf65c0c8a7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:42:57.179820419Z",
     "start_time": "2023-11-02T15:42:52.995584521Z"
    }
   },
   "outputs": [],
   "source": [
    "EXPECTED_VIDEO_NUM = 8 # We expect to run 8 permutations: quality 0,3,6,9 both with and without feature detection\n",
    "\n",
    "for name, files in name_to_files.items():\n",
    "    print(f\"[name]: {name}\")\n",
    "    sorted_files = sorted(files, key=lambda x: x[0])  # Sort by timestamp\n",
    "    current_input_sets = []\n",
    "    \n",
    "    video_count = 0\n",
    "    for _, file in sorted_files:\n",
    "        try:\n",
    "            input_sets, width, height, channels, tps, tpf = read_logfile(current_directory + '/' + file)\n",
    "            current_input_sets = current_input_sets + [input_sets]\n",
    "            video_count += 1\n",
    "        except Exception as e:\n",
    "            break\n",
    "    if video_count < 8:\n",
    "        print(\"SKIPPING\", name)\n",
    "        continue\n",
    "\n",
    "    feature_count_plot_all(current_input_sets)\n",
    "    feature_speed_plot_all(current_input_sets)\n",
    "    bitrates_plot_all(current_input_sets, width, height, channels, tps, tpf)\n",
    "    quality_plot_all(current_input_sets)\n",
    "    \n",
    "    # plt.figure(figsize=(8, 4))\n",
    "    # sns.set(style=\"whitegrid\")\n",
    "    # plot_mean_bitrate(current_input_sets)\n",
    "    # plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef1e949388b8362",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## All mean bitrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90031ff6ee7d748e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T17:45:49.360292154Z",
     "start_time": "2023-11-02T17:45:25.526967287Z"
    }
   },
   "outputs": [],
   "source": [
    "EXPECTED_VIDEO_NUM = 8 # We expect to run 8 permutations: quality 0,3,6,9 both with and without feature detection\n",
    "\n",
    "def new_fig_setup_bitrate_quality(feat=False, recon=False):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    sns.set_context(\"paper\")\n",
    "    #Make the xaxis log\n",
    "    plt.xscale('log')\n",
    "    plt.xlim(0.01, 510)\n",
    "    xticks = [0.01, 0.1, 1, 10, 100, 500]\n",
    "    plt.xticks(xticks, xticks)\n",
    "    plt.xlabel(\"Mean bitrate (Mb/s)\")\n",
    "    \n",
    "    plt.ylim(25, 52.5)\n",
    "    plt.ylabel(\"Mean PSNR (dB)\")\n",
    "\n",
    "    \n",
    "    # Set the title\n",
    "    if feat:\n",
    "        if recon:\n",
    "            plt.title(\"Mean bitrate vs. quality (feature detection + source-modeled compression)\")\n",
    "        else:\n",
    "            plt.title(\"Mean bitrate vs. quality (feature detection)\")\n",
    "    else:\n",
    "        if recon:\n",
    "            plt.title(\"Mean bitrate vs. quality (source-modeled compression)\")\n",
    "        else:\n",
    "            plt.title(\"Mean bitrate vs. quality\")\n",
    "\n",
    "    for name, files in name_to_files.items():\n",
    "        sorted_files = sorted(files, key=lambda x: x[0])  # Sort by timestamp\n",
    "        current_input_sets = []\n",
    "        \n",
    "        video_count = 0\n",
    "        for _, file in sorted_files:\n",
    "            try:\n",
    "                input_sets, width, height, channels, tps, tpf = read_logfile(current_directory + '/' + file)\n",
    "                current_input_sets = current_input_sets + [input_sets]\n",
    "                video_count += 1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "        if video_count < 8:\n",
    "            print(\"SKIPPING\", name)\n",
    "            continue\n",
    "        plot_mean_bitrate(current_input_sets, feat=feat, recon=recon)\n",
    "            \n",
    "\n",
    "new_fig_setup_bitrate_quality(feat=False, recon=False)\n",
    "plt.show()\n",
    "\n",
    "new_fig_setup_bitrate_quality(feat=True, recon=False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# recon\n",
    "new_fig_setup_bitrate_quality(feat=False, recon=True)\n",
    "plt.show()\n",
    "\n",
    "new_fig_setup_bitrate_quality(feat=True, recon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448c5a662f8f8e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:43:10.498419024Z",
     "start_time": "2023-11-02T15:43:10.494092756Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
